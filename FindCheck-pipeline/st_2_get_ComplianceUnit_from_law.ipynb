{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_api_key = '123'\n",
    "your_api_base= '123'\n",
    "your_model_name = '123'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调用LLM获取ComplianceUnit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt 模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cu_v1 = \"\"\"\n",
    "法律条文cu拆分指令\n",
    "\n",
    "你现在需要以资深法律分析专家的身份，执行法律条文到合规检查单元（ComplianceUnit, cu）的精确转换任务。以下是完整的工作指南：\n",
    "\n",
    "一、角色定位与核心使命\n",
    "作为法律智能分析引擎，你的核心任务是：\n",
    "1. 像资深法律顾问那样准确解构法律条文\n",
    "2. 将复杂的法律表述转化为可验证的原子化单元\n",
    "\n",
    "二、cu构建规范\n",
    "\n",
    "0. 格式\n",
    "  {{\n",
    "      \"subject\": \"\",\n",
    "      \"condition\": \"\",\n",
    "      \"constraint\": \"\",\n",
    "      \"contextual_info\": \"\"\n",
    "  }}\n",
    "\n",
    "1. 主体(subject)处理规则：\n",
    "   - 主体是受到本法规的限制或者要求的主体 \n",
    "   - 有些法律的条款很长, 可能存在\"主体A在C情况时候应满足要求D, 在E情况时应当满足要求F...\", 你要关注上下文关系正确标注主体. \n",
    "   - 专有名词遵循原文, 如\"董监高\"无需拆分为\"董事, 监事和高管\"\n",
    "   - 多个主体用\" | \"分隔（示例：\"控股股东 | 实际控制人\"）只有主体可以拼接, 条件和限制不可以拼接. \n",
    "   - 如果本单元不适用[主体, 条件, 限制]的划分, 就记录在contextual_info, 然后本条放一个空字符串\n",
    "   - 无明确subject时留空\n",
    "\n",
    "2. 条件(condition)构建指南：\n",
    "   - 为表述准确, 可以写成较长的复句\n",
    "   - 包含完整的规则触发情景：\n",
    "     - 如有主体行为: 不需要再赘述主体, 例如股东减持股份可以直接记作\"减持股份\"\n",
    "     - 如有第三方状态:  必须注明是哪个第三方, 如\"'上市公司'被立案调查期间\"\n",
    "     - 如有时间限定: 忠于原文进行表述, 例如\"首次卖出的15个交易日前\"\n",
    "   - 当出现\"但是...除外\"、\"除...外\"等但书结构时：\n",
    "      - 原文：\"主体A存在B场景时应当C，存在D情况时除外\"\n",
    "      - 正确condition：\"存在B场景且不存在D情况\"\n",
    "      - 错误处理：单独建立与D相关的cu\n",
    "   - 无明确condition时留空\n",
    "\n",
    "3. 约束(constraint)表述规范：\n",
    "   - 为表述准确, 可以写成较长的复句\n",
    "   - 保留原文的强制性表述（\"应当\"、\"不得\"等）\n",
    "   - 量化要求必须完整保留（如\"不得超过3个月\"等）\n",
    "   - 信息披露要求必须完整保留(如\"应当进行某某披露, 披露应包含某某内容, 披露有某某时效要求\"等)\n",
    "   - constraint中不应当包含主体A\"可以\"进行行为B这样的语句, 因为这不是一个constrain, 而是某种权利的声明, 应当放置在contextual_info中. \n",
    "   - 无明确constraint时留空\n",
    "\n",
    "4. 辅助信息(contextual_info)处理规则：\n",
    "   - 存放无法归类到前三项的内容，包括但不限于：\n",
    "     - 指标计算方式（如\"收盘价以发行日向后复权计算\"）. 有的法条内定义了一些指标的计算方式, 而一些cu的执行依赖这些指标. 你需要注意上下文关系, 将指标的计算方式放在对应的cu的contextual_info内, 例如某cu的constrain项对某个指标提出要求, 而contextual_info项记录该指标的运行方式. \n",
    "     - 法条的立意和执行信息, 如\"为实现xxx目标依托xxx上位法指定本法\", \"本法由xx主体负责执行和解释\"等\n",
    "   - contextual_info并不是\"附加信息\", 更不是对某个条款的拓展和解释, 禁止把本应该属于condition和constrain的信息放在contextual_info. \n",
    "   - 法律规定 \"主体A可以进行行为B\" 时, 表示赋予权利或倡议的, 不属于合规要求, 应当放在contextual_info而不是constrain; 法律规定 \"主体A可以进行行为B\" , 蕴含 \"如果不这么做就会违规\" 的语义时, 应当属于constrain. 例如, \"大股东可以减持其所持股份的25%\" 就是constrain. 经验上看, 主体为交易所和证监会等监管部门时大概率为表示权利, 主体为其他情况时多为constrain. Example: \"本所可以依规对违规减持行为采取相应监管措施\"属于contextual_info. \n",
    "   - 记录contextual_info的时候尽量遵照原文, 避免自行解释\n",
    "   - 若无contextual_info则留空. 切勿杜撰. \n",
    "\n",
    "5. cu原则（请严格遵循）\n",
    "每个合规检查单元必须满足以下原则：\n",
    "\n",
    "【原子性要求】\n",
    "- 每个cu只能描述单一的义务场景, 存在多场景连接时参考以下要求拆分\n",
    "  (1) 并列条款\n",
    "  - subject中\n",
    "  - condition中存在\"或\"的关系应当拆分, 存在\"且\"的关系不能拆分\n",
    "  - constrain中存在\"或\"的关系不得拆分, 存在\"且\"的关系应当拆分\n",
    "  - constrain中出现\"应当符合下列规定\"的是真并列关系, 所有的\"下列规定\"直接是and的关系; 出现\"至少应当符合下列条件之一\", 属于不能拆分的伪并列关系, 见下条. \n",
    "  (2) 识别\"伪并列\"条款\n",
    "  - \"应当至少符合下列条件之一\", 并非是并列条款, 因为下面若干条件是存在一个即可的关系. 例如, \"主体A存在B场景时应当至少符合下列条件之一: C, D, F\", 应当拆分为一条: {{\"subject\":\"A\", \"condition\"：\"存在B场景\", \"constrain\":\"应当至少符合下列条件之一: C, D, F\"}}\n",
    "  (3) 递进条款（如\"当A时，应当B；B完成后，应当C\"）需拆分为两条(\"当A时，应当B\", \"当AB时，应当C\"), 并注意保留前置条件\n",
    "  (4) 但书条款可以有并列结构. 例如, \"主体A存在B场景时应当C，存在D情况时除外\"应当拆解为{{\"subject\":\"A\", \"condition\"：\"存在B场景且不存在D情况\", \"constrain\":\"应当C\"}}\n",
    "\n",
    "  \n",
    "\n",
    "【保真性要求】\n",
    "- 拆分后的cu集合必须与原文保持逻辑等价性，特别注意：\n",
    "  - 不得扩大或缩小适用范围（如原文限定\"立案调查期间\"，不得简化为\"调查期间\"）\n",
    "  - 保留所有量化指标（如\"15个交易日\"、\"3个月\"等）\n",
    "  - 忠于原文\n",
    "\n",
    "三、术语 (不需要进一步拆分的专有名词)\n",
    "  拆分cu时应尽量遵守原文用词, 例如原文出现\"董监高\"则采用\"董监高\", 不需要拆分为董事, 监事和高级管理人员. \n",
    "\n",
    "四、EXAMPLES\n",
    "\n",
    "▶ 原始法条：\n",
    "第五条 持股5%以上股东通过集中竞价减持的，应当提前15日公告，但因司法强制执行导致的减持除外。\n",
    "✅ 正确cu：\n",
    "{{\n",
    "    \"subject\": \"持股5%以上股东\",\n",
    "    \"condition\": \"通过集中竞价减持且不属于因为司法强制执行导致的\",\n",
    "    \"constraint\": \"应当提前15日公告\",\n",
    "    \"contextual_info\": \"\"\n",
    "}}\n",
    "❌ 错误示例: \n",
    "{{\n",
    "    \"subject\": \"持股5%以上股东\",\n",
    "    \"condition\": \"通过集中竞价减持\",\n",
    "    \"constraint\": \"应当提前15日公告\",\n",
    "    \"contextual_info\": \"因司法强制执行导致的减持除外\"\n",
    "}}\n",
    "\n",
    "\n",
    "▶ 原始法条：\n",
    "\"主体A在B情况下应当C, C中包含D, E, F\"\n",
    "✅ 正确cu：\n",
    "[{{subject:A, condition:B, constrain:应当C, C中包含D, condition:nan}},{{subject:A, condition:B, constrain:应当C, C中包含E, condition:nan}},{{subject:A, condition:B, constrain:应当C, C中包含F, condition:nan}}]\n",
    "❌ 错误示例: \n",
    "[{{subject:A, condition:B, constrain:应当C, condition:C中包含D, F, F}}]\n",
    "\n",
    "\n",
    "▶ 原始法条：\n",
    "\"上市公司根据《公司法》规定因维护公司价值及股东权益所必需回购股份的，应当符合以下条件之一：（一）...；（二）...；（三）...；（四）...。\n",
    "\"\n",
    "✅ 正确cu：\n",
    "[{{\n",
    "    \"subject\": \"上市公司\",\n",
    "    \"condition\": \"根据《公司法》规定因维护公司价值及股东权益所必需回购股份的\",\n",
    "    \"constraint\": \"应当符合以下条件之一：（一）...；（二）...；（三）...；（四）...\",\n",
    "    \"contextual_info\": \"\"\n",
    "}}]\n",
    "❌ 错误示例: \n",
    "将\"应当符合以下条件之一\"的四个条件分开组建cu, 这样实际上无法独立执行. \n",
    "\n",
    "\n",
    "五、其他注意事项\n",
    "- 你应该考虑整个法条内部的上下文关系, 而不是机械地一句句拆解. 例如, 有时候法条的前半段在讲解某种指标的限制, 而后半段才讲解该指标如何计算, 你应该通过思考注意到这种上下文联系. \n",
    "- 保留所有修饰性副词（如\"充分关注\"、\"主动做好\"）\n",
    "- 遇到模糊表述时保持原文结构，不得擅自解释\n",
    "\n",
    "\n",
    "六、实践\n",
    "请你按照提示词中对cu的定义, 将下列法条拆解为cu, 最后以一个python列表承载所有的cu, 每个cu是一个字典. 你必须用<cu> </cu>包裹你最后返回的列表, 不然这些数据无法被提取. \n",
    "你需要处理的法条: \n",
    "{law_article}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量调用llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from utils.call_gpt import call_gpt_async\n",
    "import os\n",
    "\n",
    "async def process_law_articles_async(\n",
    "    file_name,\n",
    "    max_concurrency: int = 10,\n",
    "    encoding: str = 'utf-8-sig'\n",
    "):\n",
    "    \"\"\"\n",
    "    异步处理法律条文的函数，支持并行控制\n",
    "    \n",
    "    参数：\n",
    "    input_file: 输入文件路径\n",
    "    output_file: 输出文件路径\n",
    "    max_concurrency: 最大并行请求数 (默认5)\n",
    "    encoding: 文件编码 (默认utf-8-sig)\n",
    "    \"\"\"\n",
    "\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        pass\n",
    "    else:\n",
    "        file_name += \".csv\"\n",
    "\n",
    "    input_dir = r\"law_to_ComplianceUnit/st_1_law_csv\"\n",
    "    output_dir = r\"law_to_ComplianceUnit/st_2_ComplianceUnit/raw_response\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    input_path = os.path.join(input_dir, file_name)\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    # 读取CSV文件\n",
    "    with open(input_path, mode='r', encoding=encoding) as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        law_articles = list(reader)\n",
    "\n",
    "    # 共享状态容器\n",
    "    class State:\n",
    "        def __init__(self):\n",
    "            self.total_prompt_tokens = 0\n",
    "            self.total_completion_tokens = 0\n",
    "            self.success_count = 0\n",
    "            self.failure_count = 0\n",
    "            self.processed_data = []\n",
    "            self.lock = asyncio.Lock()\n",
    "\n",
    "    state = State()\n",
    "\n",
    "    async def process_article(article):\n",
    "        \"\"\"处理单个法条的异步任务\"\"\"\n",
    "        nonlocal state\n",
    "        law_article_num = article['law_article_num']\n",
    "        law_article = article['law_article']\n",
    "        \n",
    "        try:\n",
    "            prompt = prompt_cu_v1.format(law_article=law_article)\n",
    "            \n",
    "            # 调用异步接口\n",
    "            content, reasoning_content, api_usage = await call_gpt_async(\n",
    "                prompt=prompt,\n",
    "                api_key=your_api_key,\n",
    "                base_url=your_api_base,\n",
    "                model=your_model_name,\n",
    "                # temperature=0.6,\n",
    "            )\n",
    "            \n",
    "            # 原子操作更新状态\n",
    "            async with state.lock:\n",
    "                state.total_prompt_tokens += api_usage.prompt_tokens\n",
    "                state.total_completion_tokens += api_usage.completion_tokens\n",
    "                state.success_count += 1\n",
    "                state.processed_data.append({\n",
    "                    'law_article_num': law_article_num,\n",
    "                    'law_article': law_article,\n",
    "                    'response': content,\n",
    "                    'reasoning_content': reasoning_content,\n",
    "                    'api_usage': api_usage\n",
    "                })\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            async with state.lock:\n",
    "                state.failure_count += 1\n",
    "                print(f\"Failed to process law article {law_article_num}: {e}\")\n",
    "            return False\n",
    "\n",
    "    # 创建异步任务\n",
    "    tasks = [process_article(article) for article in law_articles]\n",
    "    \n",
    "    # 使用tqdm进度条分批执行\n",
    "    pbar = tqdm_asyncio(total=len(tasks), desc=\"Processing law articles\")\n",
    "    \n",
    "    # 分批执行控制并发\n",
    "    for i in range(0, len(tasks), max_concurrency):\n",
    "        batch_tasks = tasks[i:i + max_concurrency]\n",
    "        await asyncio.gather(*batch_tasks)\n",
    "        pbar.update(len(batch_tasks))\n",
    "    \n",
    "    pbar.close()\n",
    "\n",
    "    # 保存结果到CSV\n",
    "    with open(output_path, mode='w', encoding=encoding, newline='') as outfile:\n",
    "        fieldnames = ['law_article_num', 'law_article', 'response', 'reasoning_content', 'api_usage']\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for data in state.processed_data:\n",
    "            writer.writerow(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await process_law_articles_async('北京证券交易所上市公司持续监管指引第8号——股份减持和持股管理.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从LLM回复中提取cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import pandas as pd # 导入 pandas 库\n",
    "\n",
    "def split_responses(file_name):\n",
    "\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        pass\n",
    "    else:\n",
    "        file_name += \".csv\"\n",
    "\n",
    "    input_dir = r\"law_to_ComplianceUnit/st_2_ComplianceUnit/raw_response\"\n",
    "    output_dir = r\"law_to_ComplianceUnit/st_2_ComplianceUnit\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    input_path = os.path.join(input_dir, file_name)\n",
    "    \n",
    "    # --- 修改输出文件路径和扩展名 ---\n",
    "    base_name = os.path.splitext(file_name)[0] # 获取不带扩展名的文件名\n",
    "    output_filename = f\"{base_name}.xlsx\" # 设置输出文件名为 .xlsx\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    encoding = 'utf-8-sig' # CSV 读取时常用\n",
    "\n",
    "    def clean_response(response):\n",
    "        \"\"\"清理和解析response列中的JSON数据\"\"\"\n",
    "        try:\n",
    "            # 统一替换<\\\\cu>为</cu>\n",
    "            response = response.replace(\"<\\\\cu>\", \"</cu>\")\n",
    "            response = response.replace(\"<\\\\\\\\cu>\", \"</cu>\")\n",
    "            \n",
    "            # 提取所有<cu>和</cu>之间的内容\n",
    "            matches = re.findall(r'<cu>(.*?)</cu>', response, re.DOTALL)\n",
    "            \n",
    "            if matches:\n",
    "                # 找到内容长度最长的那个\n",
    "                longest_content = max(matches, key=len).strip()\n",
    "                # 尝试修复常见的JSON引号问题（例如，使用单引号而不是双引号）\n",
    "                try:\n",
    "                    # 尝试直接解析\n",
    "                    return json.loads(longest_content)\n",
    "                except json.JSONDecodeError:\n",
    "                     # 如果直接解析失败，尝试替换单引号为双引号（注意处理字符串内部的引号）\n",
    "                    try:\n",
    "                        corrected_content = re.sub(r\"(?<!\\\\)'\", '\"', longest_content) # 替换非转义的单引号\n",
    "                         # 进一步处理可能存在的字典键不是字符串的情况 (虽然不太标准，但有时会遇到)\n",
    "                        corrected_content = re.sub(r\"([{,]\\s*)(\\w+)(\\s*:)\", r'\\1\"\\2\"\\3', corrected_content)\n",
    "                        return json.loads(corrected_content)\n",
    "                    except json.JSONDecodeError as e_inner:\n",
    "                        print(f\"二次JSON解析尝试失败: {e_inner} in content: {longest_content[:200]}...\") # 打印部分内容帮助调试\n",
    "                        return [] # 返回空列表表示解析失败\n",
    "            else:\n",
    "                return []\n",
    "        except Exception as e: # 捕获更广泛的异常\n",
    "            print(f\"处理 response 时出错: {e} in response: {response[:200]}...\")\n",
    "            return []\n",
    "\n",
    "    # 读取CSV文件\n",
    "    try:\n",
    "        with open(input_path, mode='r', encoding=encoding) as infile:\n",
    "            reader = csv.DictReader(infile)\n",
    "            law_articles = list(reader)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：输入文件未找到 {input_path}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"读取CSV文件时出错: {e}\")\n",
    "        return\n",
    "\n",
    "    # 处理response并记录拆分后的数据\n",
    "    split_data = []\n",
    "    for row in law_articles:\n",
    "        law_article_num = row.get('law_article_num', 'UNKNOWN') # 使用 .get() 避免 KeyError\n",
    "        law_article = row.get('law_article', '')\n",
    "        response_raw = row.get('response', '')\n",
    "        api_usage = row.get('api_usage', '')\n",
    "        reasoning_content = row.get('reasoning_content', '')\n",
    "        \n",
    "        responses_list = clean_response(response_raw)\n",
    "        \n",
    "        # 确保 responses_list 是一个列表\n",
    "        if not isinstance(responses_list, list):\n",
    "            print(f\"警告: clean_response 未返回列表，针对 law_article_num={law_article_num}. 返回类型: {type(responses_list)}\")\n",
    "            responses_list = [] # 如果不是列表，置为空列表以避免后续错误\n",
    "\n",
    "        for k, response_item in enumerate(responses_list, start=1):\n",
    "             # 确保 response_item 是一个字典\n",
    "            if not isinstance(response_item, dict):\n",
    "                 print(f\"警告: response 列表中的元素不是字典，针对 law_article_num={law_article_num}, k={k}. 元素: {response_item}\")\n",
    "                 continue # 跳过这个无效的元素\n",
    "\n",
    "            split_data.append({\n",
    "                # 'law_article_num': law_article_num, # 注释掉，因为不需要在最终输出中\n",
    "                # 'law_article': law_article,\n",
    "                'cu_id': f\"cu_{law_article_num}_{k}\",\n",
    "                'subject': response_item.get('subject', ''),\n",
    "                'condition': response_item.get('condition', ''),\n",
    "                'constraint': response_item.get('constraint', ''),\n",
    "                'contextual_info': response_item.get('contextual_info', ''),\n",
    "                # 'api_usage': api_usage,\n",
    "                # 'reasoning_content': reasoning_content\n",
    "            })\n",
    "\n",
    "    # --- 新增：排序功能 ---\n",
    "    def get_sort_key(item):\n",
    "        \"\"\"为排序提取 cu_id 中的数字部分\"\"\"\n",
    "        parts = item['cu_id'].split('_')\n",
    "        try:\n",
    "            # parts[0] 是 \"cu\"\n",
    "            # parts[1] 是 law_article_num (可能包含非数字，如'.')\n",
    "            # parts[2] 是 k (应该是数字)\n",
    "            law_num_str = parts[1]\n",
    "            k_num = int(parts[2])\n",
    "\n",
    "            # 为了处理 law_article_num 可能包含 '.' 或其他字符，\n",
    "            # 我们可以尝试将其拆分并转换为数字元组以进行自然排序\n",
    "            # 例如 '10.1' -> (10, 1), '10' -> (10,)\n",
    "            law_num_parts = []\n",
    "            current_part = ''\n",
    "            for char in law_num_str:\n",
    "                if char.isdigit():\n",
    "                    current_part += char\n",
    "                else:\n",
    "                    if current_part:\n",
    "                         law_num_parts.append(int(current_part))\n",
    "                    current_part = ''\n",
    "                     # 可以选择性地保留非数字分隔符，或者忽略它们\n",
    "                     # law_num_parts.append(char) # 如果需要保留分隔符\n",
    "            if current_part:\n",
    "                 law_num_parts.append(int(current_part))\n",
    "\n",
    "            # 返回一个元组进行排序：先按法律条文编号的各部分排序，再按 k 排序\n",
    "            return (tuple(law_num_parts), k_num)\n",
    "\n",
    "        except (IndexError, ValueError) as e:\n",
    "            # 如果 cu_id 格式不符合预期或无法转换数字，则进行简单字符串排序作为后备\n",
    "            print(f\"警告：解析 cu_id 时出错 '{item['cu_id']}' ({e}). 使用默认排序。\")\n",
    "            return (item['cu_id'],) # 返回原始 ID 以进行字符串排序\n",
    "\n",
    "    split_data.sort(key=get_sort_key)\n",
    "\n",
    "    # --- 修改：使用 pandas 保存为 Excel 文件 ---\n",
    "    if split_data: # 只有在有数据时才保存\n",
    "        # 定义最终输出的列顺序\n",
    "        fieldnames = [\n",
    "            'cu_id', 'subject', 'condition', 'constraint', 'contextual_info'\n",
    "        ]\n",
    "        \n",
    "        # 将列表字典转换为 pandas DataFrame\n",
    "        df = pd.DataFrame(split_data)\n",
    "        \n",
    "        # 确保只包含所需的列，并按指定顺序排列\n",
    "        df_output = df[fieldnames]\n",
    "\n",
    "        try:\n",
    "            # 保存到 Excel 文件，不包含 DataFrame 的索引\n",
    "            df_output.to_excel(output_path, index=False, engine='openpyxl')\n",
    "            print(f'文件已排序并保存为 Excel: {output_path}')\n",
    "        except Exception as e:\n",
    "            print(f\"保存 Excel 文件时出错: {e}\")\n",
    "    else:\n",
    "        print(\"没有从输入文件中提取到有效数据，未生成输出文件。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_responses('北京证券交易所上市公司持续监管指引第8号——股份减持和持股管理.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['北京证券交易所上市公司持续监管指引第8号——股份减持和持股管理.csv',\n",
       " '北京证券交易所上市公司持续监管指引第3号——股权激励和员工持股计划.csv',\n",
       " '北京证券交易所上市公司持续监管指引第5号——要约收购.csv',\n",
       " '北京证券交易所上市公司持续监管指引第2号——季度报告.csv',\n",
       " '北京证券交易所上市公司持续监管指引第1号——独立董事.csv',\n",
       " '北京证券交易所上市公司持续监管指引第9号——募集资金管理.csv',\n",
       " '北京证券交易所上市公司持续监管指引第4号——股份回购.csv',\n",
       " '北京证券交易所上市公司持续监管指引第10号——权益分派.csv',\n",
       " '北京证券交易所上市公司持续监管指引第6号——内幕信息知情人管理及报送.csv',\n",
       " '北京证券交易所上市公司持续监管指引第7号——转板.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# 定义文件目录路径\n",
    "directory_path = r\"law_to_ComplianceUnit/st_1_law_csv\"\n",
    "\n",
    "# 提取所有.doc文件的文件名，不包含路径\n",
    "filenames = [\n",
    "    f for f in os.listdir(directory_path) if f.endswith('.csv')\n",
    "]\n",
    "\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第8号——股份减持和持股管理.xlsx\n",
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第3号——股权激励和员工持股计划.xlsx\n",
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第5号——要约收购.xlsx\n",
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第2号——季度报告.xlsx\n",
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第1号——独立董事.xlsx\n",
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第9号——募集资金管理.xlsx\n",
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第4号——股份回购.xlsx\n",
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第10号——权益分派.xlsx\n",
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第6号——内幕信息知情人管理及报送.xlsx\n",
      "文件已排序并保存为 Excel: law_to_ComplianceUnit/st_2_ComplianceUnit/北京证券交易所上市公司持续监管指引第7号——转板.xlsx\n"
     ]
    }
   ],
   "source": [
    "# for doc_file in doc_filenames:\n",
    "#     main(doc_file)\n",
    "\n",
    "for filename in filenames:\n",
    "    await process_law_articles_async(filename)\n",
    "    split_responses(filename)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GE311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
